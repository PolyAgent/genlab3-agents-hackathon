{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x_zGwdPymdLi"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install qdrant-client pymongo\n",
        "!pip install langchain_community pypdf langchain_text_splitters langchain_experimental\n",
        "!pip install llama-index llama-index-vector-stores-qdrant llama-index-readers-file llama-index-embeddings-fastembed qdrant_client fastembed\n",
        "!pip install openai==1.14.1\n",
        "!pip install langchainhub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATagQ1NdsHFw"
      },
      "source": [
        "# Qdrant Client (Retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "815a140e9cb340b5854d715a35de287e",
            "c053f4d4c6424384878fa833cae5ef7b",
            "f5bf10a50be14369b7f55b401c2ba96f",
            "9e60963a48c84da98ec2a3cfeaa64e94",
            "92283f79365d41bf9293f3e829365ac8",
            "5ee507724600421bb42ac2cdcd841b0e",
            "92aa7882dacd4949bd31c855b8f55b94",
            "d1298ef28c964cd994c6833b9627156e",
            "2c7151dff2e1408f9e7bd05f3602fc21",
            "7fcf55715cfe4b69b8707ee6299e7132",
            "7d10d4fd7e994d86abc055d5859b11fd"
          ]
        },
        "id": "UOdLD99EoL3p",
        "outputId": "c610f7e4-3467-490c-884e-f75b5a7583c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "815a140e9cb340b5854d715a35de287e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import qdrant_client\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
        "from llama_index.core import Document, Settings\n",
        "import os\n",
        "from qdrant_client import QdrantClient\n",
        "import openai\n",
        "\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import ConnectionFailure\n",
        "\n",
        "COLLECTION_NAME = \"vc-pilot-full\"\n",
        "\n",
        "# Set up Qdrant client for vector store\n",
        "qdrant_client = QdrantClient(\n",
        "    url='https://56ab7b97-f618-4723-9b13-93e0b140c31b.us-east4-0.gcp.cloud.qdrant.io:6333',\n",
        "    api_key=\"lBfwfnQqD1ogXoZ86-X8wFWigRoZwZk1ydOYJf4pv6WJyLQmm7jqDg\",\n",
        ")\n",
        "\n",
        "# Embedding model for vector insertion\n",
        "os.environ[\"OPENAI_API_BASE\"]=\"https://api.fireworks.ai/inference/v1\"\n",
        "os.environ[\"OPENAI_API_KEY\"] =\"soXg5G0dRAywvZyyLIOLwjKBfe6S1kqV6lC2KdEcVbWqlxM4\"\n",
        "embed_model = FastEmbedEmbedding(model_name=\"nomic-ai/nomic-embed-text-v1.5\")\n",
        "Settings.embed_model = embed_model\n",
        "\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=qdrant_client,\n",
        "    collection_name=COLLECTION_NAME\n",
        ")\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store=vector_store,\n",
        "    embed_model=embed_model\n",
        ")\n",
        "retriever = index.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dvcw6L74wEsB"
      },
      "outputs": [],
      "source": [
        "# https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_0ZW43LsAgb"
      },
      "source": [
        "## Mongo Reader (Ingestor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dwKiXJjDsC1O",
        "outputId": "ba16fe22-5b66-44ff-84b1-77b86ab2850b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22996"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MongoDBQuery:\n",
        "    def __init__(self, db_name, collection_name, uri=\"mongodb://localhost:27017/\"):\n",
        "        self.uri = uri\n",
        "        self.db_name = db_name\n",
        "        self.collection_name = collection_name\n",
        "        self.client = None\n",
        "        self.db = None\n",
        "        self.collection = None\n",
        "        self.connect()\n",
        "\n",
        "    def connect(self):\n",
        "        try:\n",
        "            self.client = MongoClient(self.uri)\n",
        "            self.client.admin.command('ping')\n",
        "            self.db = self.client[self.db_name]\n",
        "            self.collection = self.db[self.collection_name]\n",
        "        except ConnectionFailure:\n",
        "            print(\"Failed to connect to MongoDB\")\n",
        "            raise\n",
        "\n",
        "    def query(self, query_filter=None):\n",
        "        if query_filter is None:\n",
        "            query_filter = {}\n",
        "        try:\n",
        "            results = self.collection.find(query_filter)\n",
        "            return list(results)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during the query: {e}\")\n",
        "            raise\n",
        "mongo = MongoDBQuery(\n",
        "    db_name=\"arxiv\",\n",
        "    collection_name=\"papers_for_review\",\n",
        "    uri=\"mongodb+srv://genlab-hackathon:qSzbc3NWGgWie1aP@age-house.dypq7r5.mongodb.net\",\n",
        ")\n",
        "mongo_content = mongo.query(query_filter={\"abstract\": {\"$exists\": True}})\n",
        "len(mongo_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky3Y0B1U6tpB"
      },
      "source": [
        "## Insert Mongo Documents into indexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "c7cb02b343bb45b4a095d26caec0c2fb",
            "5b47dbe2e63e4151b1b6c40e33f53ddd",
            "69c44660f89a4598b3fe8cdd515d3c52",
            "c9ca7f6af1794655ba3879da496a6f77",
            "833aa6ac259d4b7a879327399fd95c0e",
            "bec85f1bc6644323bd99ca672c79b941",
            "a14f476418224be29dca0c795e61e30f",
            "766f136cf3b44efda50db7511e7a548b",
            "6d168d1f438448359da5a329d100507d",
            "1e3fe09e691c4faa9582082ddfd6ede0",
            "f6fe02a1134a49409cda85223f21935f"
          ]
        },
        "id": "IH4dIcn04qO_",
        "outputId": "b2cc58b7-4392-4493-dfc4-cb5de8569d22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7cb02b343bb45b4a095d26caec0c2fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/22996 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8dbe370b51ff>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Wait for all futures to complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8dbe370b51ff>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmax_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Number of available CPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmongo_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0muse_abstracts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0muse_papers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    CharacterTextSplitter,\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import os\n",
        "from threading import Lock\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "def process_paper(lock, progress_bar, paper, use_abstracts=True, use_papers=False):\n",
        "    if use_abstracts:\n",
        "        title = paper[\"title\"]\n",
        "        text_content = paper[\"abstract\"]\n",
        "        doc = Document(text=f\"{title}:\\n{text_content}\")\n",
        "        index.insert(doc)\n",
        "    if use_papers:\n",
        "        pdf_loader = PyPDFLoader(paper[\"pdf_url\"])\n",
        "        documents = pdf_loader.load_and_split(text_splitter=text_splitter)\n",
        "        index.insert(documents)\n",
        "    with lock:\n",
        "        progress_bar.update(1)\n",
        "\n",
        "lock = Lock()\n",
        "\n",
        "max_workers = os.cpu_count()\n",
        "progress_bar = tqdm(total=len(mongo_content))\n",
        "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "    use_abstracts = True\n",
        "    use_papers = False\n",
        "    futures = [executor.submit(process_paper, lock, progress_bar, paper, use_abstracts, use_papers) for paper in mongo_content]\n",
        "\n",
        "    for future in as_completed(futures):\n",
        "        pass\n",
        "\n",
        "progress_bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUjN16R6_wi-"
      },
      "outputs": [],
      "source": [
        "def get_relevant_documents(question):\n",
        "    relevant_documents = list(map(\n",
        "            lambda node: node.text.replace(\"\\n\", \" \"),\n",
        "            sorted(\n",
        "              retriever.retrieve(question),\n",
        "              key=lambda node: node.score,\n",
        "              reverse=True\n",
        "            ),\n",
        "    ))\n",
        "    return relevant_documents\n",
        "\n",
        "relevant_documents = get_relevant_documents(\"llm\")\n",
        "relevant_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Lb5WBEVn2D9U"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain_core.language_models.llms import LLM\n",
        "\n",
        "class FireworkLLM(LLM):\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"Firework\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        client = openai.OpenAI(\n",
        "            base_url = \"https://api.fireworks.ai/inference/v1\",\n",
        "            api_key=\"soXg5G0dRAywvZyyLIOLwjKBfe6S1kqV6lC2KdEcVbWqlxM4\",\n",
        "        )\n",
        "        response = client.chat.completions.create(\n",
        "          model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
        "          temperature=0,\n",
        "          max_tokens=4096,\n",
        "          messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "          }],\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "llm = FireworkLLM()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "mfksqaJOFa_m",
        "outputId": "fe6d12bd-c7fc-454a-b6f5-416082f8a600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROPOSAL\n",
            "Personalized learning platform using AI to adapt to student's learning pace.\n",
            "TASKS\n",
            "[\"Effectiveness of AI-driven personalized learning platforms in improving student outcomes: Examining the impact of AI-based adaptive learning platforms on student performance and engagement is crucial to predict the startup's success.\", \"Comparison of AI-driven personalized learning platforms with traditional methods: Analyzing the differences in learning outcomes, user experience, and cost-effectiveness between the proposed AI solution and traditional learning methods will help assess the startup's value proposition.\", \"Data privacy and security in AI-powered personalized learning platforms: Investigating potential data privacy and security concerns, as well as regulatory compliance, is essential to ensure the startup's solution is viable and ethically sound.\", \"User experience and interface design in AI-driven personalized learning platforms: Understanding user preferences, usability, and accessibility aspects of the proposed platform will help predict the startup's success in attracting and retaining users.\", \"Scalability and adaptability of AI-powered personalized learning platforms in various educational settings: Evaluating the applicability and adaptability of the startup's solution in diverse educational contexts, such as K-12, higher education, and corporate training, will help predict the startup's growth potential and market reach.\"]\n",
            "CHUNKS\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "from typing import List\n",
        "\n",
        "def get_research_tasks(proposal: str) -> List:\n",
        "    research_template = PromptTemplate.from_template(\n",
        "        template = \"\"\"\n",
        "    You are a research analyst for a venture capital investor that is evaluating AI technology startups.\n",
        "    You have expertise in AI field and you understand how to evaluate the risk profile for new startup ideas.\n",
        "    A startup is proposing the following idea:\n",
        "    {proposal}\n",
        "\n",
        "    Your task is to use the TRIZ methodology of problem solving to generate a list of the top 5 topics that would need to be researched.\n",
        "    The list should be prioritized based on factors that can predict the success of the startup and should be simple, concise.\n",
        "    This list will be used to search a database of 100,000 scientific papers on AI\n",
        "\n",
        "    Here is an example of independent reserach topics that may be pursued where the topic is a statup's proposal for funding on a 1-bit quantization model:\n",
        "    - Impact of 1-bit quantization on LLM performance and accuracy\": Understanding the trade-off between computational efficiency and model accuracy is crucial to predict the success of the startup's proposal.\n",
        "    - Scalability of 1-bit quantized LLMs in real-world applications\": The startup's success depends on the applicability and scalability of their solution in various industries and use-cases.\n",
        "    - Comparative analysis of 1-bit quantization with other model compression techniques\": It's essential to evaluate how the proposed solution compares to alternative methods in terms of efficiency, accuracy, and ease of implementation.\n",
        "    - Hardware and software requirements for implementing 1-bit quantized LLMs\": Understanding the infrastructure needed to support the startup's solution will help assess the overall cost, accessibility, and feasibility of their proposal.\n",
        "    - Case studies and success stories of 1-bit quantization in AI models\": Learning from previous experiences and successes can provide valuable insights into potential challenges, opportunities, and the overall viability of the startup's idea.\n",
        "\n",
        "    Respond in only `-` delimited list format with in depth independently operable research tasks.\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    prompt = research_template.format(\n",
        "        proposal=proposal,\n",
        "    )\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    tasks = list(\n",
        "              filter(\n",
        "                  lambda y: y != \"\",\n",
        "                  map(\n",
        "                      lambda x: x.strip()\\\n",
        "                                 .replace(\"- \", \"\")\\\n",
        "                                 .replace(\"\\\"\", \"\"),\n",
        "                      response.split(\"\\n\")\n",
        "                      )\n",
        "                  )\n",
        "            )\n",
        "    return tasks\n",
        "\n",
        "\n",
        "# proposal = \"LLMs demand substantial computational power for both training and inference, presenting barriers to their widespread application. The proposition of 1-bit quantization seeks to address these challenges by compressing model size and enhancing computational efficiency.\"\n",
        "proposal = \"Personalized learning platform using AI to adapt to student's learning pace.\"\n",
        "tasks = get_research_tasks(proposal)\n",
        "chunks = get_relevant_documents(proposal)\n",
        "print(\"PROPOSAL\")\n",
        "print(proposal)\n",
        "print(\"TASKS\")\n",
        "print(tasks)\n",
        "print(\"CHUNKS\")\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuQrmURXjeyf"
      },
      "source": [
        "# Agent Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XTWZ0Rx3jftB"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"document_retriever\",\n",
        "    \"Search for information of latest computer science and language model research papers. For any questions about the latest research, use this tool.\",\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    retriever_tool,\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1sP0WYKG-ty6"
      },
      "outputs": [],
      "source": [
        "agent_prompt = PromptTemplate(\n",
        "    input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
        "    template=\"\"\"\n",
        "Answer the following questions as best you can.\n",
        "You have access to the following tools that can reference the latest research on the given topic.\n",
        "Do not hallucinate.  If you do not have the relevant research to the question, simply say \"NOT ENOUGH INFORMATION\":\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, should be one of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}'\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Ob4JBkUOlU8Q",
        "outputId": "62dbcd1d-e504-45b7-eb6c-531d8b8eb4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TASK 1: Evaluating cross-encoder performance in retrieval-augmented generation: To assess the startup's core technology, research the performance of their cross-encoder in various scenarios, considering factors like precision, recall, and response time.\n",
            "RESEARCH: Based on the information provided by the research papers, I can evaluate the cross-encoder performance. However, I am unable to perform the action and observe the result.\n",
            "####################\n",
            "TASK 2: Comparison of cross-encoder approach with traditional retrieval methods: Investigate how the proposed cross-encoder technology compares to conventional retrieval techniques in terms of accuracy, complexity, and efficiency.\n",
            "RESEARCH: NOT ENOUGH INFORMATION\n",
            "####################\n",
            "TASK 3: Real-world applications and scalability of cross-encoder for retrieval-augmented generation: Explore potential use-cases and industries where the startup's technology can be applied, focusing on its adaptability and scalability.\n",
            "RESEARCH: NOT ENOUGH INFORMATION. I recommend further research on the real-world applications and scalability of cross-encoder for retrieval-augmented generation to gather more information.\n",
            "####################\n",
            "TASK 4: Integration of cross-encoder with existing search engines, recommendation systems, and data analysis tools: Examine the feasibility and challenges of integrating the startup's technology with existing platforms, including compatibility, ease of implementation, and potential improvements.\n",
            "RESEARCH: The integration of cross-encoder with existing search engines, recommendation systems, and data analysis tools is feasible, but compatibility issues and ease of implementation may vary depending on the specific platforms and cross-encoder models used. Potential improvements include better personalization, context-awareness, and understanding of complex queries in search engines and recommendation systems, as well as more accurate and contextually relevant insights in data analysis tools. However, further research is needed to address the challenges and fully realize these potential improvements.\n",
            "####################\n",
            "TASK 5: Assessing user experience and satisfaction with cross-encoder-based retrieval systems: Investigate user feedback and satisfaction levels with retrieval-augmented generation systems based on cross-encoder technology to gauge market acceptance and potential for growth.\n",
            "RESEARCH: Users have reported positive experiences with cross-encoder-based retrieval systems, citing accuracy, efficiency, and user-friendliness as key benefits. However, there are areas for improvement, such as reducing system latency and improving integration with other tools and platforms. Despite these challenges, the potential for growth in this area is significant, and researchers are actively working on addressing current limitations.\n",
            "####################\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "\n",
        "react_prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(\n",
        "  llm, tools, agent_prompt\n",
        ")\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=False,\n",
        "    handle_parsing_errors=True\n",
        ")\n",
        "\n",
        "proposal = \"Our AI startup is revolutionizing information retrieval with our state-of-the-art cross-encoder for retrieval-augmented generation. By integrating advanced natural language processing techniques, our technology understands and processes complex queries to deliver precise, contextually relevant information in real-time. Designed for scalability, our solution enhances search engines, recommendation systems, and data analysis tools, providing unmatched accuracy and speed in retrieving the exact information or content users need. Our mission is to empower businesses and developers to unlock the full potential of their data, making information access seamless and more intuitive than ever before.\"\n",
        "# proposal = \"Improving accuracy of LLM using RAG\"\n",
        "tasks = get_research_tasks(proposal)\n",
        "# print(f\"PROPOSAL: {proposal}\")\n",
        "# print(\"~\"*20)\n",
        "summaries = []\n",
        "citations = retriever.retrieve(proposal)\n",
        "for i, task in enumerate(tasks):\n",
        "    response = agent_executor.invoke({\"input\": task})\n",
        "    summary = response[\"output\"]\n",
        "    summaries.append(summary)\n",
        "    print(f\"TASK {i+1}: {task}\")\n",
        "    print(f\"RESEARCH: {summary}\")\n",
        "    # print(f\"CONTENT {citations}\")\n",
        "    print(\"#\"*20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "_3KZZ_UcskmB",
        "outputId": "3fe1dc9e-66e2-42eb-822b-9bf92cf05eca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identify Key Challenges\n",
            "- Limited understanding of cross-encoder performance without actual implementation and testing\n",
            "- Inadequate chatbot capabilities compared to human mentors\n",
            "- Potential risks associated with large language models (LLMs)\n",
            "\n",
            "Explore Potential Solutions\n",
            "- Perform thorough testing and evaluation of cross-encoder technology to assess its performance and limitations\n",
            "- Continuous improvement of chatbot capabilities to better mimic human mentor interactions\n",
            "- Implementing strict control measures and guidelines for LLM usage to minimize potential risks\n",
            "\n",
            "Assess Innovation and Trend Alignment\n",
            "- The integration of generative AI and adaptive learning in education aligns with current trends in AI and EdTech\n",
            "- The proposed cross-encoder technology has the potential to significantly improve information retrieval processes\n",
            "- Utilizing a knowledge graph for contextualization in chatbot-based explanations is an innovative approach to enhance conversational explainability\n",
            "\n",
            "Solution Potential and Risk Evaluation\n",
            "- High potential for innovation in information retrieval and adaptive learning, with the possibility of creating a more efficient and intuitive learning experience\n",
            "- Manageable risks associated with LLMs can be mitigated through proper regulation and control measures\n",
            "- The proposed solutions have the potential to disrupt traditional education and EdTech models, creating new opportunities for businesses and developers in the sector\n"
          ]
        }
      ],
      "source": [
        "def generate_highlights(proposal, citations, summaries):\n",
        "    highlights_prefix = f\"\"\"\n",
        "You are a research analyst working for a venture capital firm and you need to assess a risk profile of a deep tech startup that is working on the following proposal:\n",
        "{proposal}\n",
        "\"\"\"\n",
        "\n",
        "    highlights_chunks = \"\"\n",
        "    for i, (chunk, summary)  in enumerate(zip(chunks, summaries)):\n",
        "        highlights_chunks += f\"\"\"\n",
        "Citation {i+1}:\n",
        "{chunk}\n",
        "\n",
        "Summary {i+1}:\n",
        "{summary}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    highlights_suffix = \"\"\"\n",
        "Using these citations and summaries only - please provide a final risk report analysis using this template:\n",
        "Identify Key Challenges\n",
        "Explore Potential Solutions\n",
        "Assess Innovation and Trend Alignment\n",
        "Solution Potential and Risk Evaluation\n",
        "ONLY OUTPUT CONTENT WITHIN THESE 4 SECTIONS\n",
        "Respond in only `-` delimited list format\n",
        "\"\"\"\n",
        "    highlights_prompt = \"\\n\".join([highlights_prefix, highlights_chunks, highlights_suffix])\n",
        "    response = llm.invoke(highlights_prompt)\n",
        "    return response\n",
        "\n",
        "highlights_response = generate_highlights(proposal, citations, summaries)\n",
        "print(highlights_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "eExUoQvdsn2I",
        "outputId": "d98ab626-27dd-46da-856b-77d2960a9a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Have you identified specific methods to test and evaluate cross-encoder performance prior to implementation?\n",
            "2. What strategies are you employing to enhance your chatbot's capabilities to better match human mentors?\n",
            "3. How do you plan to address the potential risks associated with large language models?\n",
            "4. Can you provide more details on the integration of generative AI and adaptive learning in your product?\n",
            "5. What measures have you taken to ensure the cross-encoder technology aligns with current trends in AI and EdTech?\n",
            "6. How do you plan to assess and improve the limitations of your proposed cross-encoder technology?\n",
            "7. What specific steps are you taking to utilize a knowledge graph for contextualization in chatbot-based explanations?\n",
            "8. How do you envision your solutions disrupting traditional education and EdTech models?\n",
            "9. What opportunities do you foresee for businesses and developers in your proposed EdTech sector?\n",
            "10. Can you provide more information on the regulatory and control measures you plan to implement for large language models?\n"
          ]
        }
      ],
      "source": [
        "followup_questions_prompt = f\"\"\"\n",
        "You are a risk analyst working in a venture capital evaluating a deep tech startup. You have done the research on the technology and generated a risk report. Based on the risk report below, come up with 10 follow-up questions directed towards the startup founders. Be concise and critical or a kid would die. The questions cannot be answered by evaluating the risk report and should only address the important points. Limit the question to a sentence and less than 100 words.\n",
        "{highlights_response}\n",
        "\"\"\"\n",
        "followup_response = llm.invoke(followup_questions_prompt)\n",
        "print(followup_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "k0hjVQg_fAUR",
        "outputId": "0251c4b5-fd03-4e9c-fc65-01523f4194ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conclusion:\n",
            "\n",
            "The AI startup exhibits promising innovation in the field of information retrieval with its cross-encoder technology and adaptive learning approach. However, there are notable technology risks that need to be addressed. The performance of the cross-encoder remains theoretical until thoroughly tested and evaluated. The chatbot's capabilities, while aligned with current trends, are currently inadequate compared to human mentors. Lastly, the use of large language models (LLMs) presents potential risks that need to be mitigated through stringent control measures.\n",
            "\n",
            "To de-risk the investment, we recommend rigorous testing and evaluation of the cross-encoder technology, continuous improvement of chatbot capabilities, and the implementation of strict control measures for LLM usage. By addressing these challenges, the startup can unlock its full potential, disrupt traditional education and EdTech models, and create new opportunities for businesses and developers.\n",
            "\n",
            "Risk Profile: This deep tech AI startup has high potential for innovation but faces manageable technology risks, primarily around the practical application of its cross-encoder technology and the ethical use of LLMs. It's like walking a tightrope over a pit of potential failure, but with the right safety measures, it could lead to a revolutionary leap in information retrieval and adaptive learning.\n"
          ]
        }
      ],
      "source": [
        "problem_statement_prompt = f\"\"\"\n",
        "Given a press release from a startup, create a statement describing problem and proposed solution that the startup is trying to address in detail. Be concise and targeted or kids would die. Only return the statement, and keep the statement one sentence. Summarize the information and do not include specific numbers or data.\n",
        "{proposal}\n",
        "\"\"\"\n",
        "problem_statement = llm.invoke(problem_statement_prompt)\n",
        "# print(problem_statement)\n",
        "\n",
        "conclusion_prompt = f\"\"\"\n",
        "You are a research analyst working on a due diligence report for a venture capital firm and need to assess a technology risk profile of a deep tech AI startup that is working on\n",
        "{proposal}\n",
        "\n",
        "You've read all the research papers relevant to this topic, produced a preliminary report, formulated relevant questions and want to create a due diligence conclusion summary based on that. Please write a conclusion section for the report, focus on investment risks of our firm, a venture capital firm investing into early stage startups, keep it under 200 words and focus on technology risk. Be really critical analyst, like someone's job depends on this. Be dry and to the point, less verbose and more factual. And then include one-liner to describe the risk profile like you are describing it to a friend, super simple and with a bit of a humor.\n",
        "{highlights_response}\n",
        "\"\"\"\n",
        "\n",
        "conclusion = llm.invoke(conclusion_prompt)\n",
        "print(conclusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "KsPKC7fegcAO",
        "outputId": "886e7919-969b-4482-d6d7-6e6a6fee4693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI Startup Revolutionizing Information Retrieval with Cross-Encoder for Retrieval-Augmented Generation\n",
            "\n",
            "CITY, DATE — Our AI startup is thrilled to announce a significant breakthrough in information retrieval with our state-of-the-art cross-encoder for retrieval-augmented generation. This cutting-edge technology integrates advanced natural language processing techniques to understand and process complex queries, delivering precise, contextually relevant information in real-time.\n",
            "\n",
            "Our cross-encoder technology has been designed with scalability in mind, enhancing search engines, recommendation systems, and data analysis tools. By providing unmatched accuracy and speed in retrieving the exact information or content users need, we empower businesses and developers to unlock the full potential of their data. Our mission is to make information access seamless and more intuitive than ever before.\n",
            "\n",
            "Since exiting stealth a little over a year ago, our solution has already gained traction among major industry players. Companies like Johnson & Johnson and Novozymes have recognized the value of our technology, which significantly cuts down the time and number of experiments required for information retrieval.\n",
            "\n",
            "Our AI model has demonstrated its ability to produce alternate versions of proteins with desired aspects, such as increased stability. In a recent example, we used our software to produce alternate versions of T7 RNA polymerase, an RNA production enzyme, that would be more resistant to high temperatures. The results showed a remarkable 70% of the variants produced by our technology exhibited increased stability, equivalent to running four or five experimental runs in one.\n",
            "\n",
            "Our technology is not limited to drug development but can also be applied in food and industrial applications. As a user-friendly tool, Cradle does not require a machine learning engineer to operate, making it accessible to scientists and labs directly.\n",
            "\n",
            "With a $24 million A round following a $5.5 million seed last year, we will use the capital to grow our team and sales. Previous investors, including Index Ventures, Kindred Capital, Chris Gibson, Tom Glocer, and others, have participated in the round.\n",
            "\n",
            "For more information about our AI startup and the cross-encoder for retrieval-augmented generation, please visit our website at [www.yourstartupwebsite.com](http://www.yourstartupwebsite.com).\n",
            "\n",
            "###\n",
            "\n",
            "About Us\n",
            "\n",
            "Our AI startup is a leader in information retrieval, leveraging advanced natural language processing techniques to deliver precise, contextually relevant information in real-time. Our mission is to empower businesses and developers to unlock the full potential of their data, making information access seamless and more intuitive than ever before.\n"
          ]
        }
      ],
      "source": [
        "press_release = llm.invoke(f\"\"\"\n",
        "generate a press release for a startup that is working on the following proposal:\n",
        "{proposal}\n",
        "\n",
        "in the format\n",
        "Biotech and AI startup Cradle is finding success with its generative approach to protein design, landing big customers and a hefty $24 million of new investment.\n",
        "The company exited stealth a little over a year ago, just as the hype around large language models was really heating up. Many AI companies in biotech train models to natively understand molecular structure; Cradle’s insight was that the long sequences of amino acids that make up the proteins in our bodies are akin to “like an alien programming language.”\n",
        "It may not be possible for a person to learn that language, but an AI model could — and a person could work with that instead. While they still couldn’t just say “make a protein that does this,” they could ask which of 100 interesting proteins looks most likely to survive at room temperature or an acidic environment.\n",
        "The approach seems to have caught the eye of major drug development companies like Johnson & Johnson and Novozymes. Creating a useful and functional protein from scratch is generally a pretty involved process, taking perhaps years and hundreds or thousands of wet-lab experiments.\n",
        "Cradle says its tech can significantly cut down that time and the number of experiments required. Though it did not really substantiate claims of halving development time, it did provide an illustrative example from its in-house development.\n",
        "They used their software to produce alternate versions of T7 RNA polymerase, an RNA production enzyme, that would be more resistant to high temperatures. Normally, they said, a team might expect under 5% of purposefully tweaked molecules to have the desired aspect, but 70% of the variants produced by Cradle showed increased stability. That’s the equivalent of running four or five such experimental runs in one.\n",
        "In addition to T7, Cradle is working internally on “a dehalogenase that can be used to decontaminate soil, a growth factor that promotes growth through cell division commonly used in cultured meat products, a transaminase that regulates metabolic pathways and helps understand certain diseases as well as an antibody therapeutic,” said Cradle CEO and co-founder Stef van Grieken in an email to TechCrunch. “We have benchmarked our models against an in-house protein engineer using existing tools and see significant improvement in Generative AI based designs.”\n",
        "Such large improvements are possible, and small, even fractional improvements would be welcomed by the companies investing millions in these processes. But of course there is more to the drug development process than generating likely candidate molecules.\n",
        "“We have already been able to showcase the potential of our platform to accelerate the R&D phase and help our partners to bring bio-based products to market faster and more cost-effectively,” said van Grieken. “In fact, as we ourselves and several partners have now completed several rounds of experimentation on our platform, we’re seeing models generalizing very well across different types of proteins and tasks, which is incredibly exciting.”\n",
        "The tech is by no means limited to drug development and could be used in food and industrial applications as well. As with other tools of this type, part of the draw for customers is that Cradle doesn’t require a machine learning engineer to operate, but can be put directly in the hands of scientists and labs.\n",
        "I asked van Grieken his thoughts on building an EU-based biotech company (many on the team previously worked at big tech firms in Silicon Valley).\n",
        "“We have found that building in the EU has pros and cons. Fundraising for a deep-tech venture in Europe is more complicated in Europe than in the US, where there are many more modern ‘tech-bio’ investors that are interested in companies like Cradle. There is also a much larger community of like-minded founders in the Bay Area,” he said.\n",
        "“However, from a talent perspective I think Europe is underappreciated,” van Grieken continued. “For example, here in Zurich, you have all major big tech companies (Apple, Google, Facebook) represented with thousands of engineers. You have a fantastic talent pool coming out of ETH and EPFL, which are some of the best universities for computer science and molecular biology in the world. And competition for talent is definitely less intense than in the Bay Area. Finally, many of the largest pharma and biotech companies in the world are located in Europe, so we are close to our customers. I definitely think the European ecosystem is developing rapidly.”\n",
        "Cradle’s $24 million A round follows a $5.5 million seed last year. Previous investor Index Ventures led the round, with Kindred Capital (also a seed investor) participating, along with individual investors Chris Gibson, Tom Glocer and others. The company says it will use the capital to grow its team and sales, as you do.\n",
        "\"\"\")\n",
        "\n",
        "print(press_release)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0hyidUThHU5"
      },
      "source": [
        "# Final Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "QiDmB9AUhJCx"
      },
      "outputs": [],
      "source": [
        "tasks = \"- \" + \"\\n- \".join(tasks)\n",
        "final_report = f\"\"\"\n",
        "## Problem Statement\n",
        "{problem_statement}\n",
        "\n",
        "## Scope of Tasks\n",
        "{tasks}\n",
        "\n",
        "## Research\n",
        "{highlights_response}\n",
        "\n",
        "## Follow up Questions\n",
        "{followup_response}\n",
        "\n",
        "## Conclusion\n",
        "{conclusion}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "rM6gouyjhqMc",
        "outputId": "d5e7d652-c5e4-40ec-9cad-e5e318bd0d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Problem Statement\n",
            "Our AI startup is transforming information retrieval with a state-of-the-art cross-encoder, utilizing advanced NLP techniques to understand and deliver precise, contextually relevant information in real-time, enhancing search engines, recommendation systems, and data analysis tools for unmatched accuracy and speed.\n",
            "\n",
            "## Scope of Tasks\n",
            "-Evaluating cross-encoder performance in retrieval-augmented generation: To assess the startup's core technology, research the performance of their cross-encoder in various scenarios, considering factors like precision, recall, and response time.\n",
            "- Comparison of cross-encoder approach with traditional retrieval methods: Investigate how the proposed cross-encoder technology compares to conventional retrieval techniques in terms of accuracy, complexity, and efficiency.\n",
            "- Real-world applications and scalability of cross-encoder for retrieval-augmented generation: Explore potential use-cases and industries where the startup's technology can be applied, focusing on its adaptability and scalability.\n",
            "- Integration of cross-encoder with existing search engines, recommendation systems, and data analysis tools: Examine the feasibility and challenges of integrating the startup's technology with existing platforms, including compatibility, ease of implementation, and potential improvements.\n",
            "- Assessing user experience and satisfaction with cross-encoder-based retrieval systems: Investigate user feedback and satisfaction levels with retrieval-augmented generation systems based on cross-encoder technology to gauge market acceptance and potential for growth.\n",
            "\n",
            "## Research\n",
            "Identify Key Challenges\n",
            "- Limited understanding of cross-encoder performance without actual implementation and testing\n",
            "- Inadequate chatbot capabilities compared to human mentors\n",
            "- Potential risks associated with large language models (LLMs)\n",
            "\n",
            "Explore Potential Solutions\n",
            "- Perform thorough testing and evaluation of cross-encoder technology to assess its performance and limitations\n",
            "- Continuous improvement of chatbot capabilities to better mimic human mentor interactions\n",
            "- Implementing strict control measures and guidelines for LLM usage to minimize potential risks\n",
            "\n",
            "Assess Innovation and Trend Alignment\n",
            "- The integration of generative AI and adaptive learning in education aligns with current trends in AI and EdTech\n",
            "- The proposed cross-encoder technology has the potential to significantly improve information retrieval processes\n",
            "- Utilizing a knowledge graph for contextualization in chatbot-based explanations is an innovative approach to enhance conversational explainability\n",
            "\n",
            "Solution Potential and Risk Evaluation\n",
            "- High potential for innovation in information retrieval and adaptive learning, with the possibility of creating a more efficient and intuitive learning experience\n",
            "- Manageable risks associated with LLMs can be mitigated through proper regulation and control measures\n",
            "- The proposed solutions have the potential to disrupt traditional education and EdTech models, creating new opportunities for businesses and developers in the sector\n",
            "\n",
            "## Follow up Questions\n",
            "1. Have you identified specific methods to test and evaluate cross-encoder performance prior to implementation?\n",
            "2. What strategies are you employing to enhance your chatbot's capabilities to better match human mentors?\n",
            "3. How do you plan to address the potential risks associated with large language models?\n",
            "4. Can you provide more details on the integration of generative AI and adaptive learning in your product?\n",
            "5. What measures have you taken to ensure the cross-encoder technology aligns with current trends in AI and EdTech?\n",
            "6. How do you plan to assess and improve the limitations of your proposed cross-encoder technology?\n",
            "7. What specific steps are you taking to utilize a knowledge graph for contextualization in chatbot-based explanations?\n",
            "8. How do you envision your solutions disrupting traditional education and EdTech models?\n",
            "9. What opportunities do you foresee for businesses and developers in your proposed EdTech sector?\n",
            "10. Can you provide more information on the regulatory and control measures you plan to implement for large language models?\n",
            "\n",
            "## Conclusion\n",
            "Conclusion:\n",
            "\n",
            "The AI startup exhibits promising innovation in the field of information retrieval with its cross-encoder technology and adaptive learning approach. However, there are notable technology risks that need to be addressed. The performance of the cross-encoder remains theoretical until thoroughly tested and evaluated. The chatbot's capabilities, while aligned with current trends, are currently inadequate compared to human mentors. Lastly, the use of large language models (LLMs) presents potential risks that need to be mitigated through stringent control measures.\n",
            "\n",
            "To de-risk the investment, we recommend rigorous testing and evaluation of the cross-encoder technology, continuous improvement of chatbot capabilities, and the implementation of strict control measures for LLM usage. By addressing these challenges, the startup can unlock its full potential, disrupt traditional education and EdTech models, and create new opportunities for businesses and developers.\n",
            "\n",
            "Risk Profile: This deep tech AI startup has high potential for innovation but faces manageable technology risks, primarily around the practical application of its cross-encoder technology and the ethical use of LLMs. It's like walking a tightrope over a pit of potential failure, but with the right safety measures, it could lead to a revolutionary leap in information retrieval and adaptive learning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(final_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV87S-WpjG9m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e3fe09e691c4faa9582082ddfd6ede0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c7151dff2e1408f9e7bd05f3602fc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b47dbe2e63e4151b1b6c40e33f53ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec85f1bc6644323bd99ca672c79b941",
            "placeholder": "​",
            "style": "IPY_MODEL_a14f476418224be29dca0c795e61e30f",
            "value": " 50%"
          }
        },
        "5ee507724600421bb42ac2cdcd841b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c44660f89a4598b3fe8cdd515d3c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_766f136cf3b44efda50db7511e7a548b",
            "max": 22996,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d168d1f438448359da5a329d100507d",
            "value": 11506
          }
        },
        "6d168d1f438448359da5a329d100507d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "766f136cf3b44efda50db7511e7a548b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d10d4fd7e994d86abc055d5859b11fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fcf55715cfe4b69b8707ee6299e7132": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "815a140e9cb340b5854d715a35de287e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c053f4d4c6424384878fa833cae5ef7b",
              "IPY_MODEL_f5bf10a50be14369b7f55b401c2ba96f",
              "IPY_MODEL_9e60963a48c84da98ec2a3cfeaa64e94"
            ],
            "layout": "IPY_MODEL_92283f79365d41bf9293f3e829365ac8"
          }
        },
        "833aa6ac259d4b7a879327399fd95c0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92283f79365d41bf9293f3e829365ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92aa7882dacd4949bd31c855b8f55b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e60963a48c84da98ec2a3cfeaa64e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fcf55715cfe4b69b8707ee6299e7132",
            "placeholder": "​",
            "style": "IPY_MODEL_7d10d4fd7e994d86abc055d5859b11fd",
            "value": " 13/13 [00:00&lt;00:00, 202.71it/s]"
          }
        },
        "a14f476418224be29dca0c795e61e30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bec85f1bc6644323bd99ca672c79b941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c053f4d4c6424384878fa833cae5ef7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee507724600421bb42ac2cdcd841b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_92aa7882dacd4949bd31c855b8f55b94",
            "value": "Fetching 13 files: 100%"
          }
        },
        "c7cb02b343bb45b4a095d26caec0c2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b47dbe2e63e4151b1b6c40e33f53ddd",
              "IPY_MODEL_69c44660f89a4598b3fe8cdd515d3c52",
              "IPY_MODEL_c9ca7f6af1794655ba3879da496a6f77"
            ],
            "layout": "IPY_MODEL_833aa6ac259d4b7a879327399fd95c0e"
          }
        },
        "c9ca7f6af1794655ba3879da496a6f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3fe09e691c4faa9582082ddfd6ede0",
            "placeholder": "​",
            "style": "IPY_MODEL_f6fe02a1134a49409cda85223f21935f",
            "value": " 11506/22996 [1:20:05&lt;1:18:09,  2.45it/s]"
          }
        },
        "d1298ef28c964cd994c6833b9627156e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5bf10a50be14369b7f55b401c2ba96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1298ef28c964cd994c6833b9627156e",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c7151dff2e1408f9e7bd05f3602fc21",
            "value": 13
          }
        },
        "f6fe02a1134a49409cda85223f21935f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
